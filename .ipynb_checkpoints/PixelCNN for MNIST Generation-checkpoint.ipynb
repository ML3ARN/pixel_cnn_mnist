{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba61a09c",
   "metadata": {},
   "source": [
    "###### TODO\n",
    "\n",
    "1. Ensure Residual block skip connection is working correctly\n",
    "2. ensure the shapes of inputs and outputs in conv and residual blocks are what is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d290f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.activations import relu\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e414d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# check tf version and if gpu is being used\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# this is needed for training to occue on rtx 2080 super as of (2021-01-11)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48016a28",
   "metadata": {},
   "source": [
    "<b>Load the data and preprocess it, as mnist consists of greyscale images with one channel we will simply convert them to binary so that they are easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d79d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load('mnist', split=['test', 'test'], shuffle_files=True,\n",
    "                                         as_supervised=True, with_info=True)\n",
    "\n",
    "def to_binary(img, label):\n",
    "    ''' make images binary '''\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.math.round(img/255.0)\n",
    "    return img, tf.cast(img, tf.int32)\n",
    "\n",
    "ds_train = ds_train.map(to_binary)\n",
    "ds_train = ds_train.cache()\n",
    "\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(64)\n",
    "ds_test = ds_test.map(to_binary).batch(64).cache().prefetch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a27f92",
   "metadata": {},
   "source": [
    "### Custom Layers\n",
    "\n",
    "The PixelCNN will require 2 blocks of layers.\n",
    "\n",
    "1. The Masked 2D Convolution: This is used nsure that the kernel does not have informaion on the value i is predicting. This is done by setting parts of the kernel to zero (masking). There are two types of mask, Type A and B. The type A mask is where the center pixel of the kernelis also masked, in  future layers they are not. Reasoning begind this can be founnd in the paper linked in the readme.\n",
    "\n",
    "\n",
    "2. The Residual Blocks: These layers will allow the netwprk to optimize the residuals of the input features to make the network more efficient.\n",
    "\n",
    "\n",
    "The custom layers will be built by subclassing the Layer class in <i>tensorflow.keras.layers.Layer</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c728bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pixelcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "masked_conv2d (MaskedConv2D) (None, 28, 28, 128)       6400      \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_2 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_3 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_4 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_5 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_6 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 1)         65        \n",
      "=================================================================\n",
      "Total params: 389,249\n",
      "Trainable params: 389,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MaskedConv2D(layers.Layer):\n",
    "    def __init__(self, mask_type, kernel=5, filters=1):\n",
    "        super(MaskedConv2D, self).__init__()\n",
    "        self.kernel = kernel\n",
    "        self.filters = filters\n",
    "        self.mask_type = mask_type\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=[self.kernel, self.kernel, input_shape[-1], self.filters], \n",
    "                                 initializer='glorot_normal',\n",
    "                                 trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.filters,), initializer='zeros', trainable=True)\n",
    "        \n",
    "        mask = np.ones(self.kernel**2, dtype=np.float32)\n",
    "        center = len(mask) // 2\n",
    "        if self.mask_type == 'A':\n",
    "            mask[center] = 0 \n",
    "            \n",
    "        mask = mask.reshape((self.kernel, self.kernel, 1, 1))\n",
    "        \n",
    "        self.mask = tf.constant(mask, dtype=tf.float32)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        masked_w = tf.math.multiply(self.w, self.mask)\n",
    "        output = tf.nn.conv2d(inputs, masked_w, 1, \"SAME\") + self.b\n",
    "        \n",
    "        return tf.nn.relu(output)\n",
    "    \n",
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, h=32):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.forward = Sequential([MaskedConv2D('B', kernel=1, filters=h),\n",
    "                                   MaskedConv2D('B', kernel=3, filters=h),\n",
    "                                   MaskedConv2D('B', kernel=1, filters=2*h)])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.forward(inputs)\n",
    "        return x + inputs\n",
    "\n",
    "\n",
    "def buildPixelCNN(hidden_features=64, output_features=64, num_resblocks=7):\n",
    "    inputs = layers.Input(shape=[28, 28, 1])\n",
    "    x = inputs\n",
    "    x = MaskedConv2D('A', kernel=7, filters=2*hidden_features)(x)\n",
    "    for _ in range(num_resblocks):\n",
    "        x = ResidualBlock(hidden_features)(x)\n",
    "        \n",
    "    x = layers.Conv2D(output_features, (1,1), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(1, (1,1), padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name=\"pixelcnn\")\n",
    "\n",
    "pixelcnn = buildPixelCNN()\n",
    "pixelcnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c4fec",
   "metadata": {},
   "source": [
    "<b>Training the model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90aa136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 21s 78ms/step - loss: 0.1749 - binary_crossentropy: 0.1749 - val_loss: 0.0024 - val_binary_crossentropy: 0.0024\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 0.0248 - binary_crossentropy: 0.0248 - val_loss: 5.7353e-04 - val_binary_crossentropy: 5.7316e-04\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 0.0066 - binary_crossentropy: 0.0065 - val_loss: 4.4145e-05 - val_binary_crossentropy: 4.4100e-05\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 0.0103 - binary_crossentropy: 0.0103 - val_loss: 1.9939e-05 - val_binary_crossentropy: 1.9940e-05\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 0.0033 - binary_crossentropy: 0.0033 - val_loss: 5.5601e-04 - val_binary_crossentropy: 5.5576e-04\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 8.7882e-05 - binary_crossentropy: 8.7880e-05 - val_loss: 1.6329e-08 - val_binary_crossentropy: 1.6345e-08\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 0.0075 - binary_crossentropy: 0.0075 - val_loss: 3.0545e-05 - val_binary_crossentropy: 3.0511e-05\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 7.0057e-06 - binary_crossentropy: 7.0056e-06 - val_loss: 8.3309e-09 - val_binary_crossentropy: 8.3134e-09\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 5.6292e-09 - binary_crossentropy: 5.6290e-09 - val_loss: 6.5570e-10 - val_binary_crossentropy: 6.5435e-10\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 4.8199e-10 - binary_crossentropy: 4.8197e-10 - val_loss: 1.8793e-10 - val_binary_crossentropy: 1.8742e-10\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 1.5119e-10 - binary_crossentropy: 1.5118e-10 - val_loss: 1.1398e-10 - val_binary_crossentropy: 1.1366e-10\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 1.3019e-10 - binary_crossentropy: 1.3019e-10 - val_loss: 8.1490e-11 - val_binary_crossentropy: 8.1256e-11\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 7.1303e-11 - binary_crossentropy: 7.1318e-11 - val_loss: 6.2634e-11 - val_binary_crossentropy: 6.2454e-11\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 6.5780e-11 - binary_crossentropy: 6.5781e-11 - val_loss: 5.1087e-11 - val_binary_crossentropy: 5.0939e-11\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 4.7245e-11 - binary_crossentropy: 4.7243e-11 - val_loss: 4.3027e-11 - val_binary_crossentropy: 4.2901e-11\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 3.9068e-11 - binary_crossentropy: 3.9066e-11 - val_loss: 3.7097e-11 - val_binary_crossentropy: 3.6989e-11\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 3.6596e-11 - binary_crossentropy: 3.6594e-11 - val_loss: 3.2610e-11 - val_binary_crossentropy: 3.2515e-11\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 3.0651e-11 - binary_crossentropy: 3.0650e-11 - val_loss: 2.9081e-11 - val_binary_crossentropy: 2.8997e-11\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 2.6776e-11 - binary_crossentropy: 2.6775e-11 - val_loss: 2.6213e-11 - val_binary_crossentropy: 2.6137e-11\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 3.2267e-11 - binary_crossentropy: 3.2266e-11 - val_loss: 2.3836e-11 - val_binary_crossentropy: 2.3767e-11\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 2.1095e-11 - binary_crossentropy: 2.1094e-11 - val_loss: 2.1840e-11 - val_binary_crossentropy: 2.1776e-11\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.9180e-11 - binary_crossentropy: 1.9179e-11 - val_loss: 2.0142e-11 - val_binary_crossentropy: 2.0083e-11\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.6758e-11 - binary_crossentropy: 1.6757e-11 - val_loss: 1.8679e-11 - val_binary_crossentropy: 1.8625e-11\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.6009e-11 - binary_crossentropy: 1.6008e-11 - val_loss: 1.7413e-11 - val_binary_crossentropy: 1.7363e-11\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.9059e-11 - binary_crossentropy: 1.9058e-11 - val_loss: 1.6299e-11 - val_binary_crossentropy: 1.6252e-11\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.6363e-11 - binary_crossentropy: 1.6362e-11 - val_loss: 1.5305e-11 - val_binary_crossentropy: 1.5261e-11\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.3526e-11 - binary_crossentropy: 1.3525e-11 - val_loss: 1.4424e-11 - val_binary_crossentropy: 1.4382e-11\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.1959e-11 - binary_crossentropy: 1.1958e-11 - val_loss: 1.3639e-11 - val_binary_crossentropy: 1.3600e-11\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.0477e-11 - binary_crossentropy: 1.0476e-11 - val_loss: 1.2934e-11 - val_binary_crossentropy: 1.2897e-11\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.3514e-11 - binary_crossentropy: 1.3513e-11 - val_loss: 1.2304e-11 - val_binary_crossentropy: 1.2269e-11\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 9.3492e-12 - binary_crossentropy: 9.3517e-12 - val_loss: 1.1711e-11 - val_binary_crossentropy: 1.1677e-11\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.1271e-11 - binary_crossentropy: 1.1270e-11 - val_loss: 1.1186e-11 - val_binary_crossentropy: 1.1154e-11\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.0958e-11 - binary_crossentropy: 1.0957e-11 - val_loss: 1.0705e-11 - val_binary_crossentropy: 1.0675e-11\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 9.8249e-12 - binary_crossentropy: 9.8243e-12 - val_loss: 1.0265e-11 - val_binary_crossentropy: 1.0236e-11\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.0930e-11 - binary_crossentropy: 1.0929e-11 - val_loss: 9.8587e-12 - val_binary_crossentropy: 9.8303e-12\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 9.5132e-12 - binary_crossentropy: 9.5128e-12 - val_loss: 9.4791e-12 - val_binary_crossentropy: 9.4518e-12\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 1.0000e-11 - binary_crossentropy: 1.0000e-11 - val_loss: 9.1291e-12 - val_binary_crossentropy: 9.1028e-12\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 7.6482e-12 - binary_crossentropy: 7.6478e-12 - val_loss: 8.8033e-12 - val_binary_crossentropy: 8.7780e-12\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 7.6583e-12 - binary_crossentropy: 7.6585e-12 - val_loss: 8.5016e-12 - val_binary_crossentropy: 8.4771e-12\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 7.7442e-12 - binary_crossentropy: 7.7438e-12 - val_loss: 8.2217e-12 - val_binary_crossentropy: 8.1980e-12\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 7.3776e-12 - binary_crossentropy: 7.3771e-12 - val_loss: 7.9587e-12 - val_binary_crossentropy: 7.9358e-12\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 6.9483e-12 - binary_crossentropy: 6.9484e-12 - val_loss: 7.7146e-12 - val_binary_crossentropy: 7.6923e-12\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 7.3121e-12 - binary_crossentropy: 7.3117e-12 - val_loss: 7.4834e-12 - val_binary_crossentropy: 7.4618e-12\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 9.7400e-12 - binary_crossentropy: 9.7404e-12 - val_loss: 7.2617e-12 - val_binary_crossentropy: 7.2408e-12\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 7.4890e-12 - binary_crossentropy: 7.4886e-12 - val_loss: 7.0559e-12 - val_binary_crossentropy: 7.0357e-12\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 12s 74ms/step - loss: 6.7555e-12 - binary_crossentropy: 6.7552e-12 - val_loss: 6.8609e-12 - val_binary_crossentropy: 6.8412e-12\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 6.5692e-12 - binary_crossentropy: 6.5689e-12 - val_loss: 6.6786e-12 - val_binary_crossentropy: 6.6594e-12\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 13s 84ms/step - loss: 6.9830e-12 - binary_crossentropy: 6.9826e-12 - val_loss: 6.5050e-12 - val_binary_crossentropy: 6.4863e-12\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 7.5839e-12 - binary_crossentropy: 7.5836e-12 - val_loss: 6.3396e-12 - val_binary_crossentropy: 6.3214e-12\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 9.3488e-12 - binary_crossentropy: 9.3485e-12 - val_loss: 6.1817e-12 - val_binary_crossentropy: 6.1639e-12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e3c1d6a9d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixelcnn.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                 optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "                 metrics=[tf.keras.losses.BinaryCrossentropy()])\n",
    "\n",
    "pixelcnn.fit(ds_train, epochs=50, validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ccb1df",
   "metadata": {},
   "source": [
    "Use the trained model to generate digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efea9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_row = 5\n",
    "grid_col = 5\n",
    "batch = grid_row * grid_col\n",
    "h = w = 28\n",
    "\n",
    "for row in range(h):\n",
    "    for col in range(w):\n",
    "        prob = pixel_cnn.predict(images)[:, row, col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543a749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make generate images with this model we will be \"predicting\" the value of each pixel one by one.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67ac01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c395e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62eac62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1390f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
