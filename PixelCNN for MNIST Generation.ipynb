{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba61a09c",
   "metadata": {},
   "source": [
    "###### TODO\n",
    "\n",
    "1. Ensure Residual block skip connection is working correctly\n",
    "2. ensure the shapes of inputs and outputs in conv and residual blocks are what is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d290f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.activations import relu\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e414d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# check tf version and if gpu is being used\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# this is needed for training to occue on rtx 2080 super as of (2021-01-11)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48016a28",
   "metadata": {},
   "source": [
    "<b>Load the data and preprocess it, as mnist consists of greyscale images with one channel we will simply convert them to binary so that they are easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d79d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load('mnist', split=['test', 'test'], shuffle_files=True,\n",
    "                                         as_supervised=True, with_info=True)\n",
    "\n",
    "def to_binary(img, label):\n",
    "    ''' make images binary '''\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.math.round(img/255.0)\n",
    "    return img, tf.cast(img, tf.int32)\n",
    "\n",
    "ds_train = ds_train.map(to_binary)\n",
    "ds_train = ds_train.cache()\n",
    "\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(64)\n",
    "ds_test = ds_test.map(to_binary).batch(64).cache().prefetch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a27f92",
   "metadata": {},
   "source": [
    "### Custom Layers\n",
    "\n",
    "The PixelCNN will require 2 blocks of layers.\n",
    "\n",
    "1. The Masked 2D Convolution: This is used nsure that the kernel does not have informaion on the value i is predicting. This is done by setting parts of the kernel to zero (masking). There are two types of mask, Type A and B. The type A mask is where the center pixel of the kernelis also masked, in  future layers they are not. Reasoning begind this can be founnd in the paper linked in the readme.\n",
    "\n",
    "\n",
    "2. The Residual Blocks: These layers will allow the netwprk to optimize the residuals of the input features to make the network more efficient.\n",
    "\n",
    "\n",
    "The custom layers will be built by subclassing the Layer class in <i>tensorflow.keras.layers.Layer</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c728bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pixelcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "masked_conv2d (MaskedConv2D) (None, 28, 28, 128)       6400      \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_2 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_3 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_4 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_5 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_6 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 1)         65        \n",
      "=================================================================\n",
      "Total params: 389,249\n",
      "Trainable params: 389,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MaskedConv2D(layers.Layer):\n",
    "    def __init__(self, mask_type, kernel=5, filters=1):\n",
    "        super(MaskedConv2D, self).__init__()\n",
    "        self.kernel = kernel\n",
    "        self.filters = filters\n",
    "        self.mask_type = mask_type\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=[self.kernel, self.kernel, input_shape[-1], self.filters], \n",
    "                                 initializer='glorot_normal',\n",
    "                                 trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.filters,), initializer='zeros', trainable=True)\n",
    "        \n",
    "        mask = np.ones(self.kernel**2, dtype=np.float32)\n",
    "        center = len(mask) // 2\n",
    "        if self.mask_type == 'A':\n",
    "            mask[center] = 0 \n",
    "            \n",
    "        mask = mask.reshape((self.kernel, self.kernel, 1, 1))\n",
    "        \n",
    "        self.mask = tf.constant(mask, dtype=tf.float32)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        masked_w = tf.math.multiply(self.w, self.mask)\n",
    "        output = tf.nn.conv2d(inputs, masked_w, 1, \"SAME\") + self.b\n",
    "        \n",
    "        return tf.nn.relu(output)\n",
    "    \n",
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, h=32):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.forward = Sequential([MaskedConv2D('B', kernel=1, filters=h),\n",
    "                                   MaskedConv2D('B', kernel=3, filters=h),\n",
    "                                   MaskedConv2D('B', kernel=1, filters=2*h)])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.forward(inputs)\n",
    "        return x + inputs\n",
    "\n",
    "\n",
    "def buildPixelCNN(hidden_features=64, output_features=64, num_resblocks=7):\n",
    "    inputs = layers.Input(shape=[28, 28, 1])\n",
    "    x = inputs\n",
    "    x = MaskedConv2D('A', kernel=7, filters=2*hidden_features)(x)\n",
    "    for _ in range(num_resblocks):\n",
    "        x = ResidualBlock(hidden_features)(x)\n",
    "        \n",
    "    x = layers.Conv2D(output_features, (1,1), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(1, (1,1), padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name=\"pixelcnn\")\n",
    "\n",
    "pixelcnn = buildPixelCNN()\n",
    "pixelcnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c4fec",
   "metadata": {},
   "source": [
    "<b>Training the model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-relations",
   "metadata": {},
   "source": [
    "While compiling the model we use Binary Cross Entropy because each call to predict is predicting the value of a pixel, which\n",
    "can either be 0 or 1. We could use softmax to predict the pixel value of RGB images where N = 3, where N would be the number\n",
    "of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90aa136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 29s 79ms/step - loss: 0.1551 - binary_crossentropy: 0.1551 - val_loss: 0.0019 - val_binary_crossentropy: 0.0019\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 0.0228 - binary_crossentropy: 0.0228 - val_loss: 1.1557e-06 - val_binary_crossentropy: 1.1553e-06\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0295 - binary_crossentropy: 0.0295 - val_loss: 3.4210e-07 - val_binary_crossentropy: 3.4336e-07\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 5.5180e-04 - binary_crossentropy: 6.2450e-04 - val_loss: 0.1244 - val_binary_crossentropy: 0.1244\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0050 - binary_crossentropy: 0.0050 - val_loss: 2.1057e-07 - val_binary_crossentropy: 2.1308e-07\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 2.3883e-08 - binary_crossentropy: 2.3883e-08 - val_loss: 8.7539e-10 - val_binary_crossentropy: 8.7615e-10\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 7.4941e-10 - binary_crossentropy: 7.4938e-10 - val_loss: 2.1047e-10 - val_binary_crossentropy: 2.1023e-10\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 2.2718e-10 - binary_crossentropy: 2.2718e-10 - val_loss: 1.2256e-10 - val_binary_crossentropy: 1.2244e-10\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 1.0082e-10 - binary_crossentropy: 1.0082e-10 - val_loss: 8.6735e-11 - val_binary_crossentropy: 8.6655e-11\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 7.4058e-11 - binary_crossentropy: 7.4054e-11 - val_loss: 6.7324e-11 - val_binary_crossentropy: 6.7246e-11\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 6.6384e-11 - binary_crossentropy: 6.6381e-11 - val_loss: 5.4613e-11 - val_binary_crossentropy: 5.4550e-11\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 4.9379e-11 - binary_crossentropy: 4.9377e-11 - val_loss: 4.5877e-11 - val_binary_crossentropy: 4.5824e-11\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 3.4628e-11 - binary_crossentropy: 3.4626e-11 - val_loss: 3.9495e-11 - val_binary_crossentropy: 3.9448e-11\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 3.1702e-11 - binary_crossentropy: 3.1700e-11 - val_loss: 3.4628e-11 - val_binary_crossentropy: 3.4587e-11\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 3.5690e-11 - binary_crossentropy: 3.5690e-11 - val_loss: 3.0818e-11 - val_binary_crossentropy: 3.0779e-11\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 3.0137e-11 - binary_crossentropy: 3.0136e-11 - val_loss: 2.7772e-11 - val_binary_crossentropy: 2.7736e-11\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 3.3925e-11 - binary_crossentropy: 3.3923e-11 - val_loss: 2.5284e-11 - val_binary_crossentropy: 2.5249e-11\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 2.4218e-11 - binary_crossentropy: 2.4217e-11 - val_loss: 2.3175e-11 - val_binary_crossentropy: 2.3143e-11\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 2.3964e-11 - binary_crossentropy: 2.3963e-11 - val_loss: 2.1389e-11 - val_binary_crossentropy: 2.1358e-11s - loss:\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 2.0405e-11 - binary_crossentropy: 2.0404e-11 - val_loss: 1.9841e-11 - val_binary_crossentropy: 1.9812e-11\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 1.6128e-11 - binary_crossentropy: 1.6127e-11 - val_loss: 1.8479e-11 - val_binary_crossentropy: 1.8452e-11\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 1.7490e-11 - binary_crossentropy: 1.7489e-11 - val_loss: 1.7298e-11 - val_binary_crossentropy: 1.7272e-11\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 1.7193e-11 - binary_crossentropy: 1.7192e-11 - val_loss: 1.6262e-11 - val_binary_crossentropy: 1.6238e-11\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 1.5026e-11 - binary_crossentropy: 1.5026e-11 - val_loss: 1.5337e-11 - val_binary_crossentropy: 1.5314e-11\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 2.0721e-11 - binary_crossentropy: 2.0720e-11 - val_loss: 1.4515e-11 - val_binary_crossentropy: 1.4493e-11\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 12s 73ms/step - loss: 1.3772e-11 - binary_crossentropy: 1.3771e-11 - val_loss: 1.3766e-11 - val_binary_crossentropy: 1.3744e-11\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 1.6663e-11 - binary_crossentropy: 1.6662e-11 - val_loss: 1.3102e-11 - val_binary_crossentropy: 1.3081e-11\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 1.5043e-11 - binary_crossentropy: 1.5045e-11 - val_loss: 1.2493e-11 - val_binary_crossentropy: 1.2473e-11\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 1.3052e-11 - binary_crossentropy: 1.3051e-11 - val_loss: 1.1934e-11 - val_binary_crossentropy: 1.1914e-11\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 1.2059e-11 - binary_crossentropy: 1.2058e-11 - val_loss: 1.1421e-11 - val_binary_crossentropy: 1.1402e-11\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 1.6584e-11 - binary_crossentropy: 1.6591e-11 - val_loss: 1.0899e-11 - val_binary_crossentropy: 1.0881e-11\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 8.0469e-12 - binary_crossentropy: 8.0463e-12 - val_loss: 1.0463e-11 - val_binary_crossentropy: 1.0446e-11\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 9.8053e-12 - binary_crossentropy: 9.8048e-12 - val_loss: 1.0061e-11 - val_binary_crossentropy: 1.0044e-11\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 9.6273e-12 - binary_crossentropy: 9.6267e-12 - val_loss: 9.6833e-12 - val_binary_crossentropy: 9.6672e-12\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 8.2423e-12 - binary_crossentropy: 8.2418e-12 - val_loss: 9.3337e-12 - val_binary_crossentropy: 9.3180e-12\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 7.8474e-12 - binary_crossentropy: 7.8469e-12 - val_loss: 9.0083e-12 - val_binary_crossentropy: 8.9930e-12\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 7.7327e-12 - binary_crossentropy: 7.7324e-12 - val_loss: 8.7028e-12 - val_binary_crossentropy: 8.6879e-12\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 8.0777e-12 - binary_crossentropy: 8.0774e-12 - val_loss: 8.4238e-12 - val_binary_crossentropy: 8.4092e-12\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 6.2653e-12 - binary_crossentropy: 6.2649e-12 - val_loss: 8.1591e-12 - val_binary_crossentropy: 8.1450e-12\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 7.7940e-12 - binary_crossentropy: 7.7935e-12 - val_loss: 7.9107e-12 - val_binary_crossentropy: 7.8969e-12\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 6.8754e-12 - binary_crossentropy: 6.8754e-12 - val_loss: 7.6733e-12 - val_binary_crossentropy: 7.6598e-12\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 7.9306e-12 - binary_crossentropy: 7.9302e-12 - val_loss: 7.4527e-12 - val_binary_crossentropy: 7.4395e-12\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 5.4048e-12 - binary_crossentropy: 5.4046e-12 - val_loss: 7.2431e-12 - val_binary_crossentropy: 7.2302e-12\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 1.0146e-11 - binary_crossentropy: 1.0145e-11 - val_loss: 7.0450e-12 - val_binary_crossentropy: 7.0324e-12\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 1.1933e-11 - binary_crossentropy: 1.1933e-11 - val_loss: 6.8568e-12 - val_binary_crossentropy: 6.8445e-12\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 11s 72ms/step - loss: 6.3932e-12 - binary_crossentropy: 6.3930e-12 - val_loss: 6.6791e-12 - val_binary_crossentropy: 6.6671e-12\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 4.8756e-12 - binary_crossentropy: 4.8755e-12 - val_loss: 6.5078e-12 - val_binary_crossentropy: 6.4960e-12\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 6.3616e-12 - binary_crossentropy: 6.3612e-12 - val_loss: 6.3446e-12 - val_binary_crossentropy: 6.3331e-12\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 5.0966e-12 - binary_crossentropy: 5.0967e-12 - val_loss: 6.1889e-12 - val_binary_crossentropy: 6.1776e-12\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 4.6293e-12 - binary_crossentropy: 4.6292e-12 - val_loss: 6.0424e-12 - val_binary_crossentropy: 6.0314e-12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27dbdc90eb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixelcnn.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                 optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "                 metrics=[tf.keras.losses.BinaryCrossentropy()])\n",
    "\n",
    "pixelcnn.fit(ds_train, epochs=50, validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ccb1df",
   "metadata": {},
   "source": [
    "Use the trained model to generate digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3efea9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_row = 5\n",
    "# grid_col = 5\n",
    "# batch = grid_row * grid_col\n",
    "# h = w = 28\n",
    "\n",
    "# for row in range(h):\n",
    "#     for col in range(w):\n",
    "#         prob = pixel_cnn.predict(images)[:, row, col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "partial-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i is the input to the network\n",
    "img = np.ones((28, 28, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(28):\n",
    "    for col in range(28):\n",
    "        prob = pixelcnn.predict(img)[row, col, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "forty-holmes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-coach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-emergency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-brother",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "neutral-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pixelcnn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "freelance-tucson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-robert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-basin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-corner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-dietary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make generate images with this model we will be \"predicting\" the value of each pixel one by one.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67ac01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c395e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62eac62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1390f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
